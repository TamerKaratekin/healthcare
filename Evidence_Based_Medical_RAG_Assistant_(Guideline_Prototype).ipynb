{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjm1611XP8gR7VoztekoHF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TamerKaratekin/healthcare/blob/main/Evidence_Based_Medical_RAG_Assistant_(Guideline_Prototype).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Product Prototype: Evidence-Based RAG for Clinical Guidelines\n",
        "\n",
        "**Author:** Tamer Karatekin  \n",
        "**Objective:**  \n",
        "Build a **Retrieval-Augmented Generation (RAG)** prototype that answers clinical questions based *strictly* on approved medical protocols (e.g., Sepsis Guidelines), effectively eliminating AI hallucinations.\n",
        "\n",
        "**Strategic Context:**  \n",
        "Generic Large Language Models (LLMs) like ChatGPT are unsafe for direct clinical advice because they can fabricate dosage or procedures.\n",
        "In a hospital setting, **Clinical Governance** requires that AI assistants act as search engines for the \"Source of Truth\" (PDF Guidelines) rather than creative writers. This project demonstrates the architecture for a **Safe GenAI Assistant** that retrieves exact context before generating an answer, ensuring adherence to the Standard of Care.\n",
        "\n",
        "**Tech Stack:**\n",
        "*   **Orchestration:** `LangChain` (The industry standard for LLM flows).\n",
        "*   **Vector Database:** `ChromaDB` (For semantic search).\n",
        "*   **Embeddings:** `HuggingFace` (Transforming medical text into vectors).\n",
        "*   **Data Source:** Simulated 2025 Sepsis Management Protocol."
      ],
      "metadata": {
        "id": "HsLefabpb4kg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1: **Install GenAI Stack**"
      ],
      "metadata": {
        "id": "9OrtkqAAKBPp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP97DkAuJsoi",
        "outputId": "1213c9ae-e417-494e-e230-cf82a90f9c22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… GenAI Environment Configured.\n"
          ]
        }
      ],
      "source": [
        "# LangChain is the industry standard for building LLM apps (Updated for Latest LangChain v0.3+)\n",
        "!pip install -q langchain langchain-community langchain-core langchain-text-splitters langchain-huggingface langchain-chroma chromadb sentence-transformers\n",
        "\n",
        "import os\n",
        "\n",
        "# 1. Text Splitter (New Location)\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# 2. Embeddings (New Location)\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# 3. Vector Store (New Location)\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "# 4. Document Schema (The fix for your specific error)\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "print(\"âœ… GenAI Environment Configured.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 2: Ingest \"Clinical Guidelines\" (Simulated)**"
      ],
      "metadata": {
        "id": "Hx7afbcbK6ZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PM Scenario: Doctors waste hours looking up protocol PDFs.\n",
        "# We turn those PDFs into a queryable knowledge base.\n",
        "\n",
        "guideline_text = \"\"\"\n",
        "GUIDELINE TITLE: Management of Sepsis (2025 Protocol)\n",
        "1. INITIAL RESUSCITATION: For sepsis-induced hypoperfusion, administer at least 30mL/kg of IV crystalloid fluid within the first 3 hours.\n",
        "2. ANTIMICROBIAL THERAPY: Administer IV antimicrobials within 1 hour of recognition of sepsis or septic shock.\n",
        "3. VASOPRESSORS: Apply norepinephrine as the first-line agent to maintain MAP > 65 mmHg.\n",
        "4. STEROIDS: IV corticosteroids are suggested only if hemodynamics cannot be restored with fluids and vasopressors.\n",
        "\"\"\"\n",
        "\n",
        "# Chunk the text (Crucial for RAG)\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
        "docs = [Document(page_content=x) for x in text_splitter.split_text(guideline_text)]"
      ],
      "metadata": {
        "id": "bq084j_cK_Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 3: The Brain (Vector Database)**"
      ],
      "metadata": {
        "id": "_-bMRetaMKCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell creates the 'db' variable that was missing!\n",
        "\n",
        "# 1. Initialize the Embedding Model (converts text to numbers)\n",
        "embedding_function = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# 2. Create the Vector Database\n",
        "db = Chroma.from_documents(\n",
        "    documents=docs,\n",
        "    embedding=embedding_function\n",
        ")\n",
        "\n",
        "print(\"ðŸ§  Knowledge Base Vectorized & Stored in ChromaDB.\")"
      ],
      "metadata": {
        "id": "Gg5dvZ4UMOiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# Cell 4: The Retrieval Logic (No Hallucinations)**"
      ],
      "metadata": {
        "id": "hiygNQQrLVZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PM Insight: We search the DB first, then answer.\n",
        "\n",
        "def ask_guideline_bot(query):\n",
        "    # 1. Search the Vector DB for relevant chunks\n",
        "    results = db.similarity_search(query, k=2)\n",
        "\n",
        "    # 2. Construct the \"Evidence\"\n",
        "    context = \"\\n\".join([doc.page_content for doc in results])\n",
        "\n",
        "    # 3. Formulate the answer (Simulating LLM generation for GitHub demo)\n",
        "    # In production, this context goes to GPT-4 via API.\n",
        "    print(f\"â“ USER QUERY: {query}\")\n",
        "    print(f\"ðŸ”Ž RETRIEVED CONTEXT (Source of Truth):\")\n",
        "    print(f\"   '{context}'...\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    if \"30mL/kg\" in context:\n",
        "        return \"Based on the 2025 Protocol, administer 30mL/kg of IV crystalloid fluid within the first 3 hours.\"\n",
        "    elif \"norepinephrine\" in context:\n",
        "        return \"Use norepinephrine as the first-line vasopressor to maintain MAP > 65 mmHg.\"\n",
        "    else:\n",
        "        return \"I cannot find that in the approved guidelines.\""
      ],
      "metadata": {
        "id": "NIMawX0fLejn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# Cell 5: Test the Product**"
      ],
      "metadata": {
        "id": "kdAXxQBSLfY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = ask_guideline_bot(\"How much fluid for initial resuscitation?\")\n",
        "print(f\"ðŸ¤– AI ANSWER: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV49k_MgLmVn",
        "outputId": "4968bee4-9529-476b-d1a6-d96882b59a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â“ USER QUERY: How much fluid for initial resuscitation?\n",
            "ðŸ”Ž RETRIEVED CONTEXT (Source of Truth):\n",
            "   'GUIDELINE TITLE: Management of Sepsis (2025 Protocol)\n",
            "1. INITIAL RESUSCITATION: For sepsis-induced hypoperfusion, administer at least 30mL/kg of IV crystalloid fluid within the first 3 hours.\n",
            "2. ANTIMICROBIAL THERAPY: Administer IV antimicrobials within 1 hour of recognition of sepsis or septic shock.\n",
            "3. VASOPRESSORS: Apply norepinephrine as the first-line agent to maintain MAP > 65 mmHg.'...\n",
            "------------------------------\n",
            "ðŸ¤– AI ANSWER: Based on the 2025 Protocol, administer 30mL/kg of IV crystalloid fluid within the first 3 hours.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This RAG architecture solves the 'Black Box' problem of LLMs. By forcing the model to retrieve context from a curated Vector Database (Chroma) before answering, we ensure that clinical advice is grounded in approved hospital protocols, not training data hallucinations."
      ],
      "metadata": {
        "id": "IM0QRPM2Lo7h"
      }
    }
  ]
}